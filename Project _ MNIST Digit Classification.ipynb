{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project (By: Kaustuv Mishra)\n",
    "## Project : MNIST Digit Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to discover the MNIST handwritten digit recognition problem. \n",
    "It will also develop a deep learning model in Python using the Keras library that will achieve excellent results. \n",
    "Here are some questions that come to mind:\n",
    "    \n",
    "--> How does deep learning work? \n",
    "\n",
    "--> Artificial neural networks are a subfield of deep learning that applies algorithms inspired by the brain's structure and function.\n",
    "\n",
    "--> What is the purpose of using Keras?\n",
    "\n",
    "Keras is one of the most popular neural network frameworks available today.\n",
    "In my opinion, it has the following advantages:\n",
    "    \n",
    "   - Simplicity (the code itself is excellent)\n",
    "\n",
    "   - Exceptional community - Comprehensive documentation, extensive community code, popular among Kagglers, so you can get access to some really insightful Keras-based data science code.\n",
    "    \n",
    "   - Very active development.\n",
    "\n",
    "--> What is the MNIST handwritten digit recognition problem?\n",
    "- For evaluating machine learning models on handwritten digit classification, Yann LeCun, Corinna Cortes, and Christopher Burges developed the MNIST dataset. \n",
    "\n",
    "- Several documents were compiled from the National Institute of Standards and Technology (NIST).\n",
    "\n",
    "- As a result, the dataset is called the Modified NIST or MNIST dataset. \n",
    "\n",
    "- Several scanned documents were used to create images of digits, which were normalized in size and centered.\n",
    "\n",
    "- This makes it an ideal dataset for assessing models, allowing the developer to concentrate on machine learning with minimal data cleaning or preparation.\n",
    "\n",
    "- We'll walk you through creating a hand-written digit classifier using the MNIST dataset in this project. \n",
    "\n",
    "- This project could be compared to the \"Hello World\" scenario for someone who is new to deep learning.\n",
    "\n",
    "- It comprises of 70,000 annotated 28x28 pixel handwritten digit images in grayscale.\n",
    "\n",
    "- A total of 60,000 training photos and 10,000 test images make up the dataset. \n",
    "\n",
    "- There are ten distinct classes (one for each of the 10 digits).\n",
    "\n",
    "- The current task involves training a model with the 60,000 training images and thereafter analyzing its classification accuracy using the 10,000 test images.\n",
    "\n",
    "\n",
    "## Let's Get Started! (~_^)\n",
    "Let's begin by importing Numpy and providing the computer's pseudorandom number generator with a seed. \n",
    "\n",
    "This enables us to replicate our script's results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing numpy\n",
    "import numpy as np\n",
    "np.random.seed(20)  # for replicability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "\n",
    "### Load image data from MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60000 training images.\n",
      "There are 10000 testing images.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# The dataset's total number of training and test photos\n",
    "print('There are %d training images.' % len(X_train))\n",
    "print('There are %d testing images.' % len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some samples from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAEHCAYAAAAOMCS6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqWElEQVR4nO3de3RU1d3/8c8QyRAwmZZiEiIXo1zUolAugsgl9lfiAqxS2z5WW1t8rIJcbB5UKqUtqXUlik/xUsCKbQOt4oNtUVGpmlYM0NQWUSqCQtUgUUgDCknkkkCyf38g+5whEyHJzJkzyfu1Vtb6zjlnZvbMlxO+2fvsfQLGGCMAAACPdIh3AwAAQPtC8QEAADxF8QEAADxF8QEAADxF8QEAADxF8QEAADxF8QEAADxF8QEAADxF8QEAADxF8QEAADwVs+Jj8eLFys7OVqdOnTRkyBCtW7cuVm+FZiAv/kVu/Ivc+BN5SVynxeJFV6xYoby8PC1evFiXXHKJHn74YY0fP15bt25Vr169PvO5DQ0N2rVrl1JTUxUIBGLRvHbJGKPHHnusxXmRyE2skBt/MsaopqZG69at4/eZz3DO+NPxcyYrK0sdOpykb8PEwEUXXWSmTp0atu3cc881d9xxx0mfW15ebiTxE6Of73znOy3KC7khN+31Z9CgQfw+8+kP54w/f8rLy0/6/Ue956Ourk4bN27UHXfcEbY9NzdXpaWljY6vra1VbW2tfWw+vcnuKE3QaeoY7ea1W3WqVame12WXXRa2vam8SOTGK+TGn47qiNZrtTZv3qyf/vSnYfua+/sMsRGNcwbRl5qaetJjol587N27V/X19crIyAjbnpGRoYqKikbHFxYW6mc/+1mEhnXUaQF+iUZLrTkkSaecF4nceIXc+NSn/zdF4/cZYiMa5wyi71SGsWJ2wemJb26MidigOXPmqKqqyv6Ul5fHqknQqedFIjdeIzf+xe8zf+KcSVxR7/no1q2bkpKSGlWflZWVjapUSQoGgwoGg9FuBk7QUce+4//85z9h25vKi0RuvEJu/I3fZ/7FOZO4ot7zkZycrCFDhqi4uDhse3FxsUaOHBntt8Mp6vBpqtesWRO2nbzEH7nxt0GDBvH7zKc4ZxJXTKbazpo1S9ddd52GDh2qiy++WEuWLNHOnTs1derUWLwdmuF3v/udRo4cSV58iNz40/Tp0zVlyhR+n/kQ50ziiknxcfXVV+ujjz7SnXfeqd27d2vAgAFavXq1evfuHYu3QzMUFhaSF58iN/709a9/XYcOHSI3PsQ5k7gCxmfzjaqrqxUKhZSjK7lqP4qOmiN6WU+rqqpKaWlpLXoNchMb5MafopkXxAa58adTyUtMej4AAInt8ccft/GIESNs/K1vfcvG//jHPzxtExo7++yzbVxYWGjjr33taza+8MILbfz2229707CT4MZyAADAUxQfAADAUwy7IOEl9e9j44/vc7a/MuiPEY/Pfu5GG/e7cUPM2gUkMveFm2eddZaNH330URuff/75Nj5y5Ign7YLCphM///zzNt6zZ4+NFy1aZOMT10PxA3o+AACApyg+AACApxh2QcJwD6/0eex9Gz+YFXl4xe25g51sXDbxERsPmXKzjbs9/PfWNhFIaD179rTx0KFDIx7Tp49zHp52mvNfCMMusTVx4kQb//GPzu+8X/3qVzaeO3eujQ8ePOhNw1qIng8AAOApig8AAOAphl3ga9sfGWZj93CJ24hN37Bx1/9xttdve8fGe6dcbOOJ8x6y8UZXnD2UWTBo39wrfnbsGHml3KeeesrGtbW1sW5Su+Ye4nriiSdsXFJSYuNbb73Vxg0NDd40LAro+QAAAJ6i+AAAAJ5i2KW1LrrAhu/mJdn40RG/sfGwYMDGi/dn23jZggk2/sJv2u9MC/csFkma/tyzNp7YeZONb9nlDMG88ZNBNg792RkiqW/iPdwzWZ673Zn5MrHzYRu7h3Wee8c55tbl19u490/bb55aLeCcB0nnnGXjsm93t/GYia/b+JovOPcNmX/5121c/9a/Y9TA9sk9Y2XOnDknPX758uU2TqRu/kTRqZPzu+fXv/61jTdv3mzj//qv/7JxouaAng8AAOApig8AAOApig8AAOAprvlogffmO9M2//qte23cPSnFxg1qcMVOjXfT55zpn1fOc577dXO7jbv+tu1fV+C+zmP1mqZXKD33184KpO7rLYJq+VTYGWuus/HPz9xn4/2vnmHjt7/vTMGd6IqzuzvTcSWm5EaS1O8cG+/4ZoaNR1/pXM+x+Mw/nfR1dtc7KzQGavy9WmMiu+8+526M1157bRxbAkn6+c9/buPhw4fbuG/fvjaurq72tE2xQM8HAADwFMUHAADwFMMuJzitZw8bvzX7TBtvu2qxjTvoNRsv3v9FGy/4+zgb93raqeu6vLvfxj999nEbDwt2tvFHg5xhmq4taXiCcU+nPZF7xdJYTG0973+doZaDZ3/eea8/O+912U8H2fizVll1T8l9sM+50Wym7zWMGmTjj3/oDIv8ZdBSG6d1cL6fPx1wvuu+xc7wVeA059/+9kudKerXvuUMj6V8UNbq9sJx443O93/DDTfEsSWQpGAwaOPvfOc7Nn755Zdt/MEHH3jZpJhrds/H2rVr9dWvflVZWVkKBAJhS+1KkjFG+fn5ysrKUkpKinJycrRly5ZotRdN2Gf2aJP5m9aaZ/UX80dVmg/D9hsZSVL//v3Ji8fIjT+Rl8RHbhJXs4uPAwcOaODAgVq4cGHE/fPnz9eCBQu0cOFCbdiwQZmZmRo3bpxqampa3Vg0rV5HdbpCOldfiri/XMcudL333nvJi8fIjT+Rl8RHbhJXs4ddxo8fr/Hjx0fcZ4zR/fffr7lz5+qqq66SJC1btkwZGRlavny5pkyZ0ug5tbW1YTcnisdVvO6hloGrdtr4qfSnbbxov3MF/7Mzvmzj5I3O7JV+1a86L+pa+fTtm53u5i8FnS7mMZuvtvG5P37Lxk2t0vlZugW6q5s+XSnShO8zxugDvStJuuKKK5SWlnbSvEjRz03teGf4wr1yqXuYRZJCE95RLLlvOBfcdvLj3TNazr3z5rB97lkxL7zq3Ihr29AjNk6E3DTl4FXDwx7n3e0MG45O+ZuNv9DBmel1bsk0G2c9nmzjLiVv27hv9UYbN4x1/ed/qRN++JYzU6aPoj/sksh5aYnrr3dW6nX/8Zic7OTotdecIeXBgwd707BWaCu5mT17to1PP/10G8+dOzcezfFEVC84LSsrU0VFhXJzc+22YDCosWPHqrS0NOJzCgsLFQqF7E/Pnj2j2SRIOqQDqlP43SdPlheJ3HiB3PgTeUks5CbxRLX4qKiokCRlZGSEbc/IyLD7TjRnzhxVVVXZn/Ly8mg2CZLqdDji9s/Ki0RuvEBu/Im8JB5yk1hiMtsl4LqBlHSsC/PEbccFg8GwK33jYfs93WzsHmoZssG56rj7JGdYJMk126WpIZIPL0218b+vcro43QuOVa3JtPHp1e81r9FR8Fl5kaKfm9t/+fuI22M9zBJNJ86+GTHUGTJ6ZZCzWFrOeGc2QfDPzV+IzOvcNOVgt/C/T365wxlyvPOgM9SS/PTnbHz2sn86T2hwzpDmDicmHW7688dLPPPi7o4fOHBg2L5+/frZ2L0wlfsGZJ///OcVyS233GLj1atX2/iddxLnvJT8c860hHu04G9/c4Yz3cNgbU1Uez4yM4/9Z3pi9VlZWdmoNwTeSVaniNvJS/yRG38iL4mH3CSWqBYf2dnZyszMVHFxsd1WV1enkpISjRw5MppvhWZIURclK7ziJy/+QG78ibwkFnKTeJo97PLJJ5+EdceVlZVp06ZN6tq1q3r16qW8vDwVFBSob9++6tu3rwoKCtS5c2df3zNgzNnO53Hfk8U91NJcB/rWuV7TuGLn9Xs/9r6Nj7b4nT59vjmqQ/rEPj6kA6ox+9VRyeoU6Kwe5hy9p6165plnNHDgwLjkZWJnZxz9uYOR/7JMNGFDRruc8PBMZyGzpNX+z01Tui05YZG3JU6YqegI/izyOH2f+961cUtmgJ1MIpwzbj16OLPyfvvb34btcw+7uFVVVdn4kUecBfLmz59v4x07dkR8j0Tgl9y0xKhRo2w8YsQIG19wwQWRDm9STk6Ojffs2WNjv6970uzi49VXX9Wllzrz4WbNmiVJ+t73vqelS5dq9uzZOnTokKZNm6Z9+/Zp+PDhevHFF5WamtrUSyIKqvWxXtNa+/jfekOS1F299UUNU0/10XvaqltvvVX79+8nLx4iN/5EXhIfuUlczS4+cnJyZIxpcn8gEFB+fr7y8/Nb0y40U9dAur6ibzS5P6BjF2Jt375daWlpXjULIjd+RV4SH7lJXNzbRdKSns5fP/1fvsnG5+j1SIc36d+/dK4y3z7efS8Y5wrsjbXOZTZHPwhfzrk9+fn2y20cUmJdVd+Uc3/tLECWO8FZcO4U1jFr10Z05b4tp+Ltt51F2i688MKwfe7brbu5F9LauXNnxGOaq0uXLlF5nfbOfQ+Xt95yhvjLyiKfD5MnT7bxL37xCxu7ZzG5F1G77bbbbLxo0aJWtTUWuKstAADwFMUHAADwFMMuCp+Nsuxi55be95RMsPF7q8+O+NyzJziLg23r4wy1uGe1uGu865fNtHEvNb0UcFv3k37P2vhBtY1b0XdxjaI9mOUsLHaZBnnfmAT1o0rnfiINH30cx5b4m7t7XZLefPPNqLyu+8Zs7vWajq/hJElXXnmljZcuXRqV922P/vu//9vG7lk67ty677szb948G7vvX/PCCy/YeMIE5/+soqIiG7/7rjNz7Pnnn29Ns6OGng8AAOApig8AAOAphl0kzat0buk99QvOUMiTfZz7HDTc4gzNuGevLN6fbePzSm6w8VtjneGb5w6GbHz2b6K3sFiiuWXXMBu7hyUejEdjEFdJ/c6x8fTPO/f8Gb/5uzYOHW0bs6ASyUcffWRj96wL97DLmjVrPG1TW/LFL37Rxqed5vz3e/Ro5P8NBg92hiHdwyV//OMfIx2uFStW2Ni9iNmcOXMivk480fMBAAA8RfEBAAA8xbCLpI1fcmqwm4Y5C0W9kxf560n9u3Mr8e6/c11l/isndM92+cmbV9g464OtrWlqQntx9VDnwfedYZfa8cPCjmvJLeiRWHZ807n7aFoH5z4/wYe6xqM5aIbdu3fHuwkJyz185eZeQM7NfX+WH//4x816r4ceesjGmzdvbtZzvUDPBwAA8BTFBwAA8BTDLicwG5zuqXO+ffLjP3jqPBtvG+bc5vr75V+2cdbX2u9Qi9vZjzm3e9b3nfD2X/4+7LgH+yTmomMfD21v85dartNwZ1bFUdXbuMs7+2xcL/iF+2ailZWVcWxJ2/Thh5Hv8+Ve9K25PvjggxY/1wv0fAAAAE9RfAAAAE8x7NJKl/d2rkZ23yNm233OYjKpesXTNvlV/TZn0agRm75h41cGhS+Y8/PVfWwcmpA4C00tvNQZPnIvqCYd8b4xPjfgDGfGxN17B9q4/q1/x6M5bVafPs651LVr5JlEBw8etPHHHzv301mwYIGN58+fb+MzzjgjYty5c2cb33XXXTb+wx/+EPZ+q1atOqW2t0WBQCBiHAtjx461cWuGb2KFng8AAOApig8AAOAphl1a4N+/HG7jZ9MX27jfn53bHPdbwVDLZ+n6P0783HOdwva5h2FGrHaGZ/w4BJPU3+nWnth5k41vXe4sqNZbf/eySWgH3Ldal6Szzz7bxjfddJON3bdedw+LuNXV1dn4k08+sXFTwzTuYZQ9e5wZbO42hULO/awqKirCnt+eh13cs4bccbR07NjRxlOnTrXx73//+0iHx1Wzej4KCws1bNgwpaamKj09XZMmTdK2bdvCjjHGKD8/X1lZWUpJSVFOTk7YKm2IjTLztv5p/qo15imVmGf0L1OqA6bxOF9hYSG58dDHJX89aV7Mp9cK9e/fn7x4iHMm8XHOJK5mFR8lJSWaPn26XnnlFRUXF+vo0aPKzc3VgQMH7DHz58/XggULtHDhQm3YsEGZmZkaN26cLy94aUv2a4966BwN06UarNEyatDrWqd6E772xKJFi8iNhw7tePekeSnXsR6de++9l7x4iHMm8XHOJK6AaUXfz549e5Senq6SkhKNGTNGxhhlZWUpLy9PP/zhDyVJtbW1ysjI0D333BPWBdiU6upqhUIh5ehKnRboeNLjPXPRBTZ89smlNnbfwyV36nQbd3rmn540qyl1plZr9YyGaKw+HzhDR0ydSrRK+fn5mjdvniT/5MY9dCFJ05971sYTOx+2cfZzN9q4343xuf/LifehOXGBtOOaWijtxLwYY7ROz6pOtaqqqlJaWlqz8yL5+LxxSer2BRsvfd3pep+240ob14ze62mb3GJ5zkRDRoZzP5wHHnggbN/VV1/drNdy35/F/V+Au/fgX//6V3ObGNGyZcvCHr/55ptNHNl80ThnvNS9e3cbv/rqqzZ2zw5y35PlVLiHWtzPvfjii23snvmyd2/sz7HjefksrbrgtKqqSpIzNlhWVqaKigrl5ubaY4LBoMaOHavS0tKIr1FbW6vq6uqwH7Te0U+nd3bUsXHYwzo2ne7LX3ZWXiU33jsxL4d0QHWqDTvmZHmRyE0scM4kLs6ZxNPi4sMYo1mzZmnUqFEaMGCAJOfCIneFfvzxiRcdHVdYWKhQKGR/evbs2dIm4VPGGG3Xv/Q5fUGnB45V9sf/g0tPTw87ltx4J3JeDkc89rPyIpGbaOOcSXycM4mlxbNdZsyYoTfeeEPr169vtO/ExVOMMU0uqDJnzhzNmjXLPq6urvbNP4rqa0bYeO3/LrJxBzmf5aLCH9g4/Zmmq24vbdMmfaIqDVVOo31+zI178TEpfMhixiPOMEfZxEecg3Y5oXvBsiNPO4sedXu4ebNM3MM//8lxXufO24ts7J7RIknPHXRm6iyaeLlrT+OZOZ+VlxN9Vl4kf583Tdn9rf42/kKHFBuXP9LXxp9TfIZdEuGcufbaa218qsMszz7rDGH+4he/sPHf/vY3Gx850jYWwUuEc8Y93FVQUGBjd27cHnvsMRu7ZzQNHOgszPejH/3IxocPO3/MuEcgvBhqaa4WFR8zZ87UqlWrtHbtWvXo0cNuz8zMlHSsB8Q9tlVZWdmoN+S4YDCoYDDYkmYggrfN69qjXRqqHHUKOFPrknXsO/7Pf/6jfv362e3kxhtN56VTxOM/Ky8SuYkmzpm2gXMmsTRr2MUYoxkzZmjlypV66aWXlJ2dHbY/OztbmZmZKi4uttvq6upUUlKikSNHRqfFiMgY8+kv0Q81RGOUEugStr+Tjv1SXbNmjd1GbmLvZHlJURf7n9xx5MUbnDNtB3lJPM0qPqZPn65HH31Uy5cvV2pqqioqKlRRUaFDhw5JOtY9mZeXp4KCAj355JN68803NXnyZHXu3DmsyxDRt02vq0I7NUDDlaSOqjWHVWsOq94cuzF54NOhogULFpAbD500L4GAeugcSdIzzzxDXjzEOZP4OGcSV7OGXY5P48nJyQnbXlRUpMmTJ0uSZs+erUOHDmnatGnat2+fhg8frhdffFGpqalRabCXzv+BMyXMPaXWfZ1H9985x9R706yIPtB7kqSNKgnbfr6GKktn2cc333xzQuXGPaV2yJSbbXzJjc40tbAb0w1yPXlec99t00mPcE/3laTz/nefjU+8dkU6tbz0VB+9p6269dZbtX///oTIS0uErtgVcXva+5Evuo21RDtnnnzySRtff/31Yft27XK+2xUrVti4qKhIbVkinzOLFi2KuN19/cfChQsjHuNez+TBBx+0sXvKrnvlWj9qVvFxKkuCBAIB5efnKz8/v6VtQgt8JfCNkx+kYxddFRYWxrg1OO5U8nL8L+zt27efdG48oodzJvFxziQubiwHAAA8xY3lTvDefGdVuBd6OavFXb/TWWgofaEzpTaeQy3tjXvq7LaHne0T+jt/wb73bWeK7OeGOje9aq6mpuz2U/jKquS/Zd49esjGHXdV2Zjvs2k7duyw8YUXXhi/hiDq3EMwTQ3HtDX0fAAAAE9RfAAAAE8x7CLpoxucoZa/futeG79y2LUK4xxnFcYkveZNw3BK3LNMev+08YyTlonW6+C4b/Vwhqw21WbZuP7f78WjOQDiiJ4PAADgKYoPAADgKYZdJFX9P+fK++5JzlDLjLKJNk5aw1AL0Fw7fu4MaU79nDN7rM/Lk218ziks7gagbaHnAwAAeIriAwAAeIphF0nuReMX7T/HxvXfTvK+MUAbcqRrQ8TtGU9ya3OgPaPnAwAAeIriAwAAeIphF0nnXLvJxn/W51x7PvS6KUCb0nf6P2x82fRBNj5d/4hwNID2gp4PAADgKd/1fBhz7PLPozoSfiUoWuWojkhyvt+WIDexQW78KZp5QWyQG386le/Wd8VHTU2NJGm9Vse5JW1TTU2NQqFQi58rkZtYITf+FI28IDbIjT+dSl4CxmflX0NDg3bt2iVjjHr16qXy8nKlpaXFu1meqK6uVs+ePWPymY0xqqmpUVZWljp0aNloG7nxd262bdum888/n7xECedM6yRCbtrjOSPFLjfNyYvvej46dOigHj16qLq6WpKUlpbWrv5RSLH7zC39C+E4cuPv3Jx55pmSyEs0cc60np9z057PGSk2n/tU88IFpwAAwFMUHwAAwFO+LT6CwaDmzZunYLD9LMOcKJ85UdoZTYnwmROhjdGWKJ85UdoZTYnwmROhjbHgh8/tuwtOAQBA2+bbng8AANA2UXwAAABPUXwAAABPUXwAAABP+bL4WLx4sbKzs9WpUycNGTJE69ati3eToqawsFDDhg1Tamqq0tPTNWnSJG3bti3sGGOM8vPzlZWVpZSUFOXk5GjLli1xanE4ckNuvEZe/Ivc+Jfvc2N85v/+7/9Mx44dzSOPPGK2bt1qfvCDH5guXbqY999/P95Ni4rLLrvMFBUVmTfffNNs2rTJTJw40fTq1ct88skn9pi7777bpKammj/96U9m8+bN5uqrrzbdu3c31dXVcWw5uTGG3MQDefEvcuNffs+N74qPiy66yEydOjVs27nnnmvuuOOOOLUotiorK40kU1JSYowxpqGhwWRmZpq7777bHnP48GETCoXMr371q3g10xhDbsiNP5AX/yI3/uW33Phq2KWurk4bN25Ubm5u2Pbc3FyVlpbGqVWxVVVVJUnq2rWrJKmsrEwVFRVh30EwGNTYsWPj+h2QG3LjF+TFv8iNf/ktN74qPvbu3av6+nplZGSEbc/IyFBFRUWcWhU7xhjNmjVLo0aN0oABAyTJfk6/fQfkhtz4AXnxL3LjX37Mje/uaitJgUAg7LExptG2tmDGjBl64403tH79+kb7/Pod+LVd0UZu/Im8+Be58S8/5sZXPR/dunVTUlJSo6qrsrKyUXWW6GbOnKlVq1ZpzZo16tGjh92emZkpSb77DsgNuYk38uJf5Ma//JobXxUfycnJGjJkiIqLi8O2FxcXa+TIkXFqVXQZYzRjxgytXLlSL730krKzs8P2Z2dnKzMzM+w7qKurU0lJSVy/A3JDbuKFvPgXufEv3+cm5pe0NtPx6U+/+c1vzNatW01eXp7p0qWL2bFjR7ybFhU333yzCYVC5uWXXza7d++2PwcPHrTH3H333SYUCpmVK1eazZs3m2uuucZXU9PIDbnxEnnxL3LjX37Pje+KD2OMWbRokendu7dJTk42gwcPtlOD2gJJEX+KiorsMQ0NDWbevHkmMzPTBINBM2bMGLN58+b4NdqF3JAbr5EX/yI3/uX33AQ+bSQAAIAnfHXNBwAAaPsoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKcoPgAAgKdiVnwsXrxY2dnZ6tSpk4YMGaJ169bF6q0AAEACiUnxsWLFCuXl5Wnu3Ll6/fXXNXr0aI0fP147d+6MxdsBAIAEEjDGmGi/6PDhwzV48GA99NBDdtt5552nSZMmqbCw8DOf29DQoF27dik1NVWBQCDaTWu3jDGqqalRVlaWOnRgtA0AED+nRfsF6+rqtHHjRt1xxx1h23Nzc1VaWtro+NraWtXW1trHH374oc4///xoNwufKi8vV48ePeLdDABAOxb1P4H37t2r+vp6ZWRkhG3PyMhQRUVFo+MLCwsVCoXsD4VHbKWmpsa7CQCAdi5m/e8nDpkYYyIOo8yZM0dVVVX2p7y8PFZNghrnBQAAr0V92KVbt25KSkpq1MtRWVnZqDdEkoLBoILBYLSbAQAAfCrqPR/JyckaMmSIiouLw7YXFxdr5MiR0X47AACQYKLe8yFJs2bN0nXXXaehQ4fq4osv1pIlS7Rz505NnTo1Fm8HAAASSEyKj6uvvlofffSR7rzzTu3evVsDBgzQ6tWr1bt371i8HQAASCAxWeejNaqrqxUKheLdjDarqqpKaWlp8W4GAKAdY7UpAADgKYoPAADgKYoPAADgKYoPAADgKYoPAADgKYoPAADgKYoPAADgKYoPAADgKYoPAADgKYoPAADgKYoPAADgKYoPAADgqZjc1TaeunTpYuNOnTrZ+PLLLw87btCgQTFtxwMPPGDjHTt2xPS9AABIJPR8AAAAT1F8AAAAT1F8AAAATyXsNR/XXHONjUeNGmXjSy65xMYXXHCBp21ymzBhgo1Hjx5t48rKyng0BwAA36DnAwAAeIriAwAAeCpgjDHxboRbdXW1QqHQSY9zN7uhoSFiXF5e3uTz161bZ+M9e/bY+K233jrltkrSgAEDbHzLLbdEPOa2226z8X333des14+2qqoqpaWlxbUNAID2rdk9H2vXrtVXv/pVZWVlKRAI6Kmnngrbb4xRfn6+srKylJKSopycHG3ZsiVa7QUAAAmu2cXHgQMHNHDgQC1cuDDi/vnz52vBggVauHChNmzYoMzMTI0bN041NTWtbiwAAEh8zZ7tMn78eI0fPz7iPmOM7r//fs2dO1dXXXWVJGnZsmXKyMjQ8uXLNWXKlNa11mX79u02rq2ttfFdd91l4yeeeCJq7+fWs2dPG48ZM+akx7PCKQAAjqhecFpWVqaKigrl5ubabcFgUGPHjlVpaWnE59TW1qq6ujrsBwAAtF1RLT4qKiokSRkZGWHbMzIy7L4TFRYWKhQK2R93rwIAAGh7YrLIWCAQCHtsjGm07bg5c+Zo1qxZ9nF1dfUpFSD9+/dvXSOb6ayzzrLxH/7wBxsPHjw44vFPP/20jf/yl7/ErF0AACSaqBYfmZmZko71gHTv3t1ur6ysbNQbclwwGFQwGIxmMwAAgI9FddglOztbmZmZKi4uttvq6upUUlKikSNHRvOtAABAgmp2z8cnn3yid955xz4uKyvTpk2b1LVrV/Xq1Ut5eXkqKChQ37591bdvXxUUFKhz58669tpro9rwWOncubONv/KVr9h4yZIlNj7jjDNO+jo/+clPbMw0YwAAHM0uPl599VVdeuml9vHx6zW+973vaenSpZo9e7YOHTqkadOmad++fRo+fLhefPFFpaamRq/VAAAgYTW7+MjJydFnrcgeCASUn5+v/Pz81rQLAAC0UTGZ7ZLI3EXTrbfe2uLXWbRokY2bGnbZuHGjjZcuXWpjFiUDALRl3NUWAAB4iuIDAAB4imGXE/Tp0ycqrzN69OiTHjNhwgQbn3feeTY+cWZQfX19VNoEAIAf0PMBAAA8RfEBAAA8FTCfNW82DqqrqxUKheL2/ueff76Nu3bt2qznupeQv+6662xcVFRk4969e9v4nnvusXFycrKNT7wDsHtdlaNHjzarTSeqqqpSWlpaq14DAIDWoOcDAAB4iuIDAAB4itkuJ9i6dWuzjr/kkktsPHPmTBt/97vftfHOnTsjPnf9+vU2fvjhh2184k34+vXr1+L2AQDgN/R8AAAAT1F8AAAATzHs0gIjRoyw8d13323j22+/3cZNDbW4vfbaazZ+7LHHbDx48OCw44qLi2185plnNq+xAAD4DD0fAADAUxQfAADAUwy7tMBtt91m45SUFBtv27atxa/5z3/+08ZHjhwJ25eZmdni1wUAwG/o+QAAAJ6i+AAAAJ5i2KUFunXrZuMvfelLNn788cdtXFBQYOO1a9dGfJ1vfvObNr7iiits3LFjx6i0EwAAP6LnAwAAeKpZxUdhYaGGDRum1NRUpaena9KkSY0usjTGKD8/X1lZWUpJSVFOTo62bNkS1UYDAIDE1axhl5KSEk2fPl3Dhg3T0aNHNXfuXOXm5mrr1q3q0qWLJGn+/PlasGCBli5dqn79+umuu+7SuHHjtG3bNqWmpsbkQ3ht06ZNNh49erSNx40bZ2P3PV/27t0b8XXcC4YlJSU1+X433HBDS5oJAIAvNav4eP7558MeFxUVKT09XRs3btSYMWNkjNH999+vuXPn6qqrrpIkLVu2TBkZGVq+fLmmTJnS6DVra2tVW1trH1dXV7fkcwAAgATRqms+qqqqJEldu3aVJJWVlamiokK5ubn2mGAwqLFjx6q0tDTiaxQWFioUCtmfnj17tqZJAADA5wLGGNOSJxpjdOWVV2rfvn1at26dJKm0tFSXXHKJPvzwQ2VlZdljb7rpJr3//vt64YUXGr1OpJ4PvxcgwWDQxg888ICNb7zxxqi8/iOPPBL2ePr06Taur69v1WtXVVUpLS2tVa8BAEBrtHiq7YwZM/TGG29o/fr1jfYFAoGwx8aYRtuOCwaDYf+ZAwCAtq1Fwy4zZ87UqlWrtGbNGvXo0cNuP74MeEVFRdjxlZWVysjIaEUzAQBAW9Gs4sMYoxkzZmjlypV66aWXlJ2dHbY/OztbmZmZYbeAr6urU0lJiUaOHBmdFgMAgITWrGs+pk2bpuXLl+vpp59W//797fZQKGRvsHbPPfeosLBQRUVF6tu3rwoKCvTyyy+f8lTb6upqhUKhFnyU+EhOTrbx6aefbmP3zB73iqhNcd9Y7oknngjb18LLciLimg8AQLw165qPhx56SJKUk5MTtr2oqEiTJ0+WJM2ePVuHDh3StGnTtG/fPg0fPlwvvvhim1njAwAAtE6zio9T+Qs8EAgoPz9f+fn5LW0TAABow1o81TZWEm3YJdEw7AIAiDduLAcAADxF8QEAADxF8QEAADxF8QEAADxF8QEAADxF8QEAADxF8QEAADxF8QEAADxF8QEAADxF8QEAADxF8QEAADxF8QEAADxF8QEAADzlu+LDZzfZbXP4fgEA8ea74qOmpibeTWjT+H4BAPEWMD77U7ihoUG7du2SMUa9evVSeXm50tLS4t0sT1RXV6tnz54x+czGGNXU1CgrK0sdOviu5gQAtCOnxbsBJ+rQoYN69Oih6upqSVJaWlq7KT6Oi9VnDoVCUX9NAACaiz+BAQCApyg+AACAp3xbfASDQc2bN0/BYDDeTfFMe/zMAID2x3cXnAIAgLbNtz0fAACgbaL4AAAAnqL4AAAAnqL4AAAAnqL4AAAAnvJl8bF48WJlZ2erU6dOGjJkiNatWxfvJkVNYWGhhg0bptTUVKWnp2vSpEnatm1b2DHGGOXn5ysrK0spKSnKycnRli1b4tRiAACiy3fFx4oVK5SXl6e5c+fq9ddf1+jRozV+/Hjt3Lkz3k2LipKSEk2fPl2vvPKKiouLdfToUeXm5urAgQP2mPnz52vBggVauHChNmzYoMzMTI0bN46bwgEA2gTfrfMxfPhwDR48WA899JDddt5552nSpEkqLCyMY8tiY8+ePUpPT1dJSYnGjBkjY4yysrKUl5enH/7wh5Kk2tpaZWRk6J577tGUKVPi3GIAAFrHVz0fdXV12rhxo3Jzc8O25+bmqrS0NE6tiq2qqipJUteuXSVJZWVlqqioCPsOgsGgxo4d22a/AwBA++Kr4mPv3r2qr69XRkZG2PaMjAxVVFTEqVWxY4zRrFmzNGrUKA0YMECS7OdsL98BAKD9OS3eDYgkEAiEPTbGNNrWFsyYMUNvvPGG1q9f32hfe/kOAADtj696Prp166akpKRGf+FXVlY26glIdDNnztSqVau0Zs0a9ejRw27PzMyUpHbxHQAA2idfFR/JyckaMmSIiouLw7YXFxdr5MiRcWpVdBljNGPGDK1cuVIvvfSSsrOzw/ZnZ2crMzMz7Duoq6tTSUlJm/kOAADtm++GXWbNmqXrrrtOQ4cO1cUXX6wlS5Zo586dmjp1arybFhXTp0/X8uXL9fTTTys1NdX2cIRCIaWkpCgQCCgvL08FBQXq27ev+vbtq4KCAnXu3FnXXnttnFsPAEDr+W6qrXRskbH58+dr9+7dGjBggO677z6NGTMm3s2Kiqau2ygqKtLkyZMlHesd+dnPfqaHH35Y+/bt0/Dhw7Vo0SJ7USoAAInMl8UHAABou3x1zQcAAGj7KD4AAICnKD4AAICnKD4AAICnKD4AAICnKD4AAICnKD4AAICnKD4AAICnKD4AAICnKD4AAICnKD4AAICn/j82/fMeoTlXsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting a few random photos in grayscale and the preset formats.\n",
    "plt.subplot(351)\n",
    "plt.imshow(X_train[57])\n",
    "plt.subplot(352)\n",
    "plt.imshow(X_train[68])\n",
    "plt.subplot(353)\n",
    "plt.imshow(X_train[42])\n",
    "plt.subplot(354)\n",
    "plt.imshow(X_train[24], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(355)\n",
    "plt.imshow(X_train[18], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(356)\n",
    "plt.imshow(X_train[30], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "# displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine whether or not the input photos from the dataset need to be preprocessed before being given as input to the neural networks, we also need to look at their dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training dataset:\n",
      "(60000, 28, 28)\n",
      "Shape of the testing dataset:\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# printing the shape of training dataset\n",
    "print ('Shape of the training dataset:') \n",
    "print (X_train.shape)\n",
    "\n",
    "# printing the shape of testing dataset\n",
    "print ('Shape of the testing dataset:')\n",
    "print (X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preprocessing**\n",
    "\n",
    "### Reshaping Dimesions\n",
    "Our next step is to prepare the inputs for Keras. Our input is organised as a three-dimensional array in the form of (60000, 28, 28), which denotes that the photos in the dataset are 28x28 in height and depth. However, keras requires a 4d array for input. The depth of the image requires that we add a dimension. MNIST images only have a depth of 1, while a full-color image with all three RGB channels will have three. By simply utilising the **reshape()** method on the NumPy array, we can easily add this dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions after reshaping:\n",
      "(60000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the input data \n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "\n",
    "# Printing the new dimensions\n",
    "print('Dimensions after reshaping:')\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the Pixel values\n",
    "Each pixel that makes up a picture that is stored on a computer has a pixel value that specifies its brightness and/or intended colour. The pixel value in binary images is often a 1-bit number that denotes either the foreground or the background. The pixel value for a grayscale image is a single number that denotes the brightness of the pixel. The byte image, which stores this number as an 8-bit integer with a possible range of values from 0 to 255, is the most popular pixel format. Normally, 255 is considered to be white while zero is considered to be black. The many colours of grey are made up of values in between. When utilising neural network models, scaling the input values is usually always a smart idea. We can rapidly normalise the pixel values to the range [0, 1] because the scale is widely understood and well handled. To do this, divide each value by the highest possible value, 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the data type to float64 \n",
    "X_train = X_train.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "\n",
    "# Normalizing pixel values\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the class labels for Keras\n",
    "This is a problem of multi-class classification classification. 0 to 9 is the range of integers in the output variable. We need the labels to be in 10 different classes, but right now they are all in one array with 10 classes. We only need to use one hot encoding to solve this. In Keras, there is a built-in assistance method called **np utils.to categorical()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries needed for encoding\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Encoding the labels\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model architecture terminology**\n",
    "A high-level API is offered by the Keras layers module, which makes it simple to build a neural network. It offers techniques for adding activation functions, applying dropout regularisation, and creating dense (completely linked) layers and convolutional layers. This section teaches you how to construct a convolutional neural network model using layers to identify the handwritten digits in the MNIST data set.\n",
    "\n",
    "###  What is CNN?\n",
    "For image classification tasks, convolutional neural networks (CNNs) are the most advanced model architecture currently available. CNNs employ a succession of filters to extract and learn higher-level characteristics from an image's raw pixel data, which the model can subsequently use for categorization. Increasing the depth of the image while reducing its height and depth is our goal as we add more layers. The depth of the image determines how many patterns the model will discover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 26, 26)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 32, 13, 13)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 11, 11)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 5, 5)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64, 5, 5)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               204928    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries for establishing the model architecture\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from keras import backend as K\n",
    "from subprocess import check_output\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "# Defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(filters = 32, kernel_size = 3, activation='relu', input_shape=(1,28,28)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(filters = 64, kernel_size = 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling and Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "300/300 [==============================] - 19s 60ms/step - loss: 0.3924 - accuracy: 0.8772\n",
      "Epoch 2/2\n",
      "300/300 [==============================] - 18s 59ms/step - loss: 0.1282 - accuracy: 0.9615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ba864bd700>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# Fitting the model on training data\n",
    "model.fit(X_train, Y_train, batch_size=200, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test set's error rate and accuracy are as follows : \n",
      "[0.050385069102048874, 0.9829999804496765]\n",
      "<keras.layers.reshaping.up_sampling2d.UpSampling2D object at 0x000001BAF1072AF0>\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import UpSampling2D\n",
    "\n",
    "\n",
    "# Evaluating the model on test data\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print (\"The test set's error rate and accuracy are as follows : \")\n",
    "print (score)\n",
    "print(UpSampling2D(size=(2, 2), data_format=None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
